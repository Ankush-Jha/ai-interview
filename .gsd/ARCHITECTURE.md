# Architecture

> Auto-generated by /map on 2026-02-15

## Overview

AI Interview Platform — a voice-first, AI-powered mock interview tool. Users upload a resume/document, configure interview settings, and enter a live conversational interview with an AI interviewer that speaks questions, listens via mic, evaluates answers, and generates a detailed report.

```
┌───────────────────────────────────────────────────────┐
│                    React Frontend                      │
│  (Vite + React 19 + Tailwind + Firebase Auth)         │
│                                                        │
│  Dashboard → Configure → Session → Results → History   │
├───────────────────────────────────────────────────────┤
│                   Express Backend                      │
│  (Node.js + HuggingFace Inference + Firebase Admin)   │
│                                                        │
│  /api/analyze · /api/questions · /api/evaluate         │
│  /api/report  · /api/generate-intro · /api/upload      │
├───────────────────────────────────────────────────────┤
│                  External Services                     │
│  HuggingFace (LLM) · Firebase (Auth+DB) · Web Speech  │
└───────────────────────────────────────────────────────┘
```

## Components

### Pages (src/pages/)
- **Dashboard.jsx** — Landing page after login, shows past sessions and quick-start
- **Configuration.jsx** — Interview settings: persona, difficulty, question count, coding mode
- **InterviewSession.jsx** — Core conversational interview loop: voice I/O, AI follow-ups, auto-advance
- **Results.jsx** — Post-interview report with scores, strengths, improvements
- **History.jsx** — Past interview sessions from Firestore
- **Login.jsx / Signup.jsx** — Firebase email/password authentication

### Components (src/components/)
- **AIOrb.jsx** — Animated AI state indicator (idle/thinking/speaking/listening)
- **CodeEditor.jsx** — Monaco-based code editor for coding interview questions
- **SessionSidebar.jsx** — Progress tracker, question navigator, shortcuts
- **VoiceControls.jsx** — Mic/speaker control UI
- **ErrorBoundary.jsx** — React error boundary wrapper
- **ProtectedRoute.jsx** — Auth guard for protected pages
- **layout/** — AppLayout, Header, Sidebar (shell layout)

### Context (src/context/)
- **AuthContext.jsx** — Firebase Auth state management (login/signup/logout)
- **InterviewContext.jsx** — Interview state machine (questions, answers, evaluations, conversation history, follow-ups, phases)

### Hooks (src/hooks/)
- **useSpeechSynthesis.js** — Web Speech API TTS with Chrome workarounds
- **useSpeechRecognition.js** — Web Speech API STT (continuous mode)
- **useSoundEffects.js** — UI sound effects (submitted, success, skip, complete)
- **useDocumentTitle.js** — Dynamic page titles
- **useTypewriter.js** — Typewriter text animation

### Libraries (src/lib/)
- **conversation.js** — Conversational flow logic: evaluateAndDecide, getIntro, getTransition, getWrapUp
- **gemini.js** — AI API proxy layer (calls backend endpoints)
- **firebase.js** — Firebase client SDK config
- **firestore.js** — Firestore CRUD for sessions/history
- **pdf-parser.js** — Client-side PDF text extraction via pdfjs-dist
- **code-runner.js** — Browser-based code execution sandbox

### Server (server/)
- **index.js** — Express entry point (CORS, helmet, rate limiting)
- **routes/ai.js** — AI API routes (analyze, questions, evaluate, report, follow-up, intro, transition, wrapup)
- **routes/upload.js** — File upload handling via multer
- **lib/hf-client.js** — HuggingFace Inference client with model chain fallback (5 models)
- **lib/prompts.js** — All LLM prompt templates
- **lib/code-sandbox.js** — Server-side code execution sandbox
- **middleware/auth.js** — Firebase Admin token verification
- **middleware/rateLimit.js** — Express rate limiting

## Data Flow

1. **Upload** → User uploads PDF → `pdf-parser.js` extracts text → `/api/analyze` sends to LLM → returns analysis + topics
2. **Configure** → User sets persona, difficulty, question count → stored in InterviewContext
3. **Generate** → `/api/questions` generates questions from analysis → stored in InterviewContext
4. **Interview Loop**:
   - AI speaks question (Web Speech TTS) → Mic listens (Web Speech STT) → User answers
   - Silence detection auto-submits → `/api/evaluate-conversational` evaluates + decides action
   - Actions: `follow_up` (probe deeper), `next_question` (auto-advance), `repeat_question`, `off_topic`, `wrap_up`
5. **Report** → `/api/report` generates comprehensive report → stored in Firestore → Results page displays

## Integration Points

| Service | Type | Purpose |
|---------|------|---------|
| HuggingFace Inference API | LLM | All AI generation (questions, evaluation, feedback, report) |
| Firebase Auth | Auth | User login/signup/session management |
| Firebase Firestore | Database | Interview history, session persistence |
| Web Speech API (TTS) | Browser | AI voice output |
| Web Speech API (STT) | Browser | User voice input |
| Monaco Editor | Browser | In-browser code editing for coding questions |

## Technical Debt

- [ ] `.next/` directory exists but project uses Vite — leftover from previous Next.js setup
- [ ] `@huggingface/inference` duplicated in both frontend and server `package.json`
- [ ] `src/utils/prompts.js` may overlap with `server/lib/prompts.js`
- [ ] No server-side tests running (jest configured but no test files in `server/`)
- [ ] `tests/prompts.test.js` exists but test coverage unclear
- [ ] No CI/CD pipeline configured
- [ ] Rate limiter is basic (in-memory, resets on server restart)

## Conventions

**Naming:** PascalCase components, camelCase functions/hooks, kebab-case files in server
**Structure:** Feature-based page organization, shared hooks/context/lib layers
**State:** React Context + useReducer for interview state, Firebase for auth
**Styling:** Tailwind CSS 3.4 with custom design tokens
**API Pattern:** Frontend `gemini.js` proxy → Express routes → `hf-client.js` → HuggingFace
